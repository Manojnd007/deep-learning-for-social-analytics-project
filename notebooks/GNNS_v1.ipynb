{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fada9-1a5d-4006-a9e4-9549b042e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#  Spotify ID, Popularity, Followers, Genre columns\n",
    "nodes_df = pd.read_csv(\"nodes_cleaned.csv\") \n",
    "#  Spotify ID 1, Spotify ID 2\n",
    "edges_df = pd.read_csv(\"edges_cleaned.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d76357-0b48-4da7-a33a-b2db78bb5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are just resetting the index and will raise an value error if we found duplicate ids\n",
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    nodes_df = nodes_df.drop_duplicates(subset=['spotify_id']).reset_index(drop=True)\n",
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    raise ValueError(\"Duplicate Spotify IDs found in nodes_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15389b53-34de-4725-aa16-ccec902c4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining genre columns Total 14 attributes including unknown\n",
    "genre_columns = [\n",
    "    'alternative Indie', 'classical_orchestral', 'electronic', 'folk world',\n",
    "    'hazz', 'hip_hop', 'latin', 'metal', 'pop', 'randb_Soul',\n",
    "    'reggae_dancehall', 'rock', 'soundtrack', 'unknown'\n",
    "]\n",
    "# Mapping Spotify IDs to indices for graph construction\n",
    "node_index_map = {spotify_id: idx for idx, spotify_id in enumerate(nodes_df['spotify_id'])}\n",
    "edges_df['Source'] = edges_df['id_0'].map(node_index_map)\n",
    "edges_df['Target'] = edges_df['id_1'].map(node_index_map)\n",
    "\n",
    "\n",
    "# Creating edge index (two rows: source and target nodes)\n",
    "edge_index = torch.tensor(edges_df[['Source', 'Target']].to_numpy().T, dtype=torch.long)\n",
    "\n",
    "# Creating node features\n",
    "node_features = torch.tensor(\n",
    "    nodes_df[['popularity', 'followers'] + genre_columns].to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd2a50-6656-4d16-8392-2eb45d028563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to generate negative edges\n",
    "def generate_negative_edges(num_nodes, existing_edges, num_samples):\n",
    "    \"\"\"\n",
    "    Generate negative edges by sampling random node pairs that are not connected.\n",
    "    \"\"\"\n",
    "    existing_edges_set = set(map(tuple, existing_edges.T.tolist()))  # Convert to set for fast lookup\n",
    "    negative_edges = set()\n",
    "\n",
    "    while len(negative_edges) < num_samples:\n",
    "        i, j = np.random.randint(0, num_nodes, size=2)\n",
    "        if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "            negative_edges.add((i, j))\n",
    "\n",
    "    return torch.tensor(list(negative_edges), dtype=torch.long)\n",
    "\n",
    "# Generating negative edges\n",
    "num_negative_samples = len(edges_df)\n",
    "negative_edges = generate_negative_edges(len(nodes_df), edge_index, num_negative_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00ee74-2821-42b4-ac3f-048664951e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining positive and negative edges for training\n",
    "positive_edges = edge_index.T\n",
    "all_edges = torch.cat([positive_edges, negative_edges], dim=0)\n",
    "labels = torch.cat([torch.ones(len(positive_edges)), torch.zeros(len(negative_edges))])\n",
    "\n",
    "# Train-test split for edges\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(\n",
    "    all_edges, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Converting to PyTorch Geometric Data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c8233-df86-427a-92f4-6ac5b25d214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GraphSAGE Model for Link Prediction\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        # Combining two embeddings\n",
    "        self.edge_predictor = torch.nn.Linear(hidden_dim * 2, 1) \n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.conv1(data.x, data.edge_index))\n",
    "        x = F.relu(self.conv2(x, data.edge_index))\n",
    "        return x\n",
    "\n",
    "    def predict_edges(self, x, edges):\n",
    "        # Combine node embeddings for edge prediction\n",
    "        edge_embeds = torch.cat([x[edges[:, 0]], x[edges[:, 1]]], dim=1)\n",
    "        return torch.sigmoid(self.edge_predictor(edge_embeds)).squeeze()\n",
    "\n",
    "# Initializing model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(data.num_node_features, hidden_dim=32).to(device)\n",
    "data = data.to(device)\n",
    "train_edges, train_labels = train_edges.to(device), train_labels.to(device)\n",
    "test_edges, test_labels = test_edges.to(device), test_labels.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data)\n",
    "    pred = model.predict_edges(embeddings, train_edges)\n",
    "    loss = F.binary_cross_entropy(pred, train_labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd18c7a9-0401-467c-8475-62edd4b0ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "        pred = model.predict_edges(embeddings, test_edges)\n",
    "        pred_labels = (pred > 0.5).float()\n",
    "        accuracy = (pred_labels == test_labels.float()).sum() / len(test_labels)\n",
    "    return accuracy.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98e6694-8d43-4069-96ec-2ec124a77dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010, Loss: 0.4056, Test Accuracy: 0.8508\n",
      "Epoch 020, Loss: 0.2928, Test Accuracy: 0.8919\n",
      "Epoch 030, Loss: 0.2444, Test Accuracy: 0.9144\n",
      "Epoch 040, Loss: 0.2219, Test Accuracy: 0.9221\n",
      "Epoch 050, Loss: 0.2124, Test Accuracy: 0.9263\n",
      "Epoch 060, Loss: 0.2068, Test Accuracy: 0.9281\n",
      "Epoch 070, Loss: 0.2030, Test Accuracy: 0.9303\n",
      "Epoch 080, Loss: 0.2002, Test Accuracy: 0.9322\n",
      "Epoch 090, Loss: 0.1978, Test Accuracy: 0.9334\n",
      "Epoch 100, Loss: 0.1956, Test Accuracy: 0.9342\n",
      "Epoch 110, Loss: 0.1986, Test Accuracy: 0.9353\n",
      "Epoch 120, Loss: 0.1924, Test Accuracy: 0.9364\n",
      "Epoch 130, Loss: 0.1918, Test Accuracy: 0.9366\n",
      "Epoch 140, Loss: 0.1903, Test Accuracy: 0.9363\n",
      "Epoch 150, Loss: 0.1891, Test Accuracy: 0.9368\n",
      "Epoch 160, Loss: 0.1881, Test Accuracy: 0.9377\n",
      "Epoch 170, Loss: 0.1872, Test Accuracy: 0.9382\n",
      "Epoch 180, Loss: 0.1863, Test Accuracy: 0.9386\n",
      "Epoch 190, Loss: 0.1855, Test Accuracy: 0.9390\n",
      "Epoch 200, Loss: 0.1848, Test Accuracy: 0.9396\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f14806-847b-463f-bdd5-acd60d28f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Converting existing edges to a set for fast lookup\n",
    "existing_edges_set = set(map(tuple, edge_index.T.tolist())) \n",
    "\n",
    "# Number of unseen pairs to sample\n",
    "num_samples = 100\n",
    "unseen_pairs = []\n",
    "\n",
    "# Randomly sampling node pairs and check if they're not connected\n",
    "while len(unseen_pairs) < num_samples:\n",
    "    i, j = random.sample(range(len(nodes_df)), 2)\n",
    "    \n",
    "    # Ensuring the pair is not already an existing edge\n",
    "    if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "        unseen_pairs.append((i, j))\n",
    "\n",
    "# Converting to tensor\n",
    "unseen_pairs = torch.tensor(unseen_pairs, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639c188-520a-4355-8504-c84889c2bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(data)\n",
    "    # predicting for unseen pairs\n",
    "    predictions = model.predict_edges(embeddings, unseen_pairs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe936a-d2a8-44c3-ad87-7e0e49adc1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 1: Arsh Sandhu, Artist 2: Petit Biscuit, Predicted Score: 0.9785\n",
      "Artist 1: prodbypengg, Artist 2: SHAED, Predicted Score: 0.9457\n",
      "Artist 1: Jheo Chavoso, Artist 2: PATAY, Predicted Score: 0.9337\n",
      "Artist 1: Bendik HK, Artist 2: Mnogoznaal, Predicted Score: 0.7793\n",
      "Artist 1: Start, Artist 2: Wolf, Predicted Score: 0.7744\n",
      "Artist 1: 5ALVO, Artist 2: Tobee, Predicted Score: 0.7499\n",
      "Artist 1: Alfred Hui, Artist 2: Billian LLD, Predicted Score: 0.7434\n",
      "Artist 1: A Si, Artist 2: LO'99, Predicted Score: 0.7151\n",
      "Artist 1: 031CHOPPA, Artist 2: Diamante 0.1, Predicted Score: 0.6917\n",
      "Artist 1: Masta Killa, Artist 2: Dawn McCarthy, Predicted Score: 0.6311\n"
     ]
    }
   ],
   "source": [
    "# Ranking unseen pairs by predicted score\n",
    "sorted_indices = torch.argsort(predictions, descending=True)\n",
    "top_predictions = unseen_pairs[sorted_indices]\n",
    "top_scores = predictions[sorted_indices]\n",
    "\n",
    "# Converting back to artist IDs for better interpretability\n",
    "top_collaborations = [\n",
    "    (nodes_df.iloc[i]['spotify_id'], nodes_df.iloc[j]['spotify_id'], score.item())\n",
    "    for (i, j), score in zip(top_predictions.tolist(), top_scores)\n",
    "]\n",
    "\n",
    "# Displaying top 10 predicted collaborations with artist names for now\n",
    "for pair in top_collaborations[:10]:\n",
    "    spotify_id_1, spotify_id_2 = pair[0], pair[1]\n",
    "    \n",
    "    # Searching for the Spotify ID in the nodes_df and print the respective artist names\n",
    "    artist_1_name = nodes_df[nodes_df['spotify_id'] == spotify_id_1]['name'].values[0]\n",
    "    artist_2_name = nodes_df[nodes_df['spotify_id'] == spotify_id_2]['name'].values[0]\n",
    "    \n",
    "    print(f\"Artist 1: {artist_1_name}, Artist 2: {artist_2_name}, Predicted Score: {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9008055-1afb-42e8-a66f-dad43176ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
