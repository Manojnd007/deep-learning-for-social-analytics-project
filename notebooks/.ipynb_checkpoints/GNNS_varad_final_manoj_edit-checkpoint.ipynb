{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435fada9-1a5d-4006-a9e4-9549b042e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13265/4278976696.py:17: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nodes_df = pd.read_csv(\"nodes_cleaned.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading cleaned nodes and edges data\n",
    "nodes_df = pd.read_csv(\"nodes_cleaned.csv\")  \n",
    "edges_df = pd.read_csv(\"edges_cleaned.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d76357-0b48-4da7-a33a-b2db78bb5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    nodes_df = nodes_df.drop_duplicates(subset=['spotify_id']).reset_index(drop=True)\n",
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    raise ValueError(\"Duplicate Spotify IDs found in nodes_df.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15389b53-34de-4725-aa16-ccec902c4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining genre columns\n",
    "genre_columns = [\n",
    "    'alternative Indie', 'classical_orchestral', 'electronic', 'folk world',\n",
    "    'jazz', 'hip_hop', 'latin', 'metal', 'pop', 'randb_Soul',\n",
    "    'reggae_dancehall', 'rock', 'soundtrack', 'unknown'\n",
    "]\n",
    "# Mapping Spotify IDs to indices for graph construction\n",
    "node_index_map = {spotify_id: idx for idx, spotify_id in enumerate(nodes_df['spotify_id'])}\n",
    "edges_df['Source'] = edges_df['id_0'].map(node_index_map)\n",
    "edges_df['Target'] = edges_df['id_1'].map(node_index_map)\n",
    "\n",
    "\n",
    "# Creating edge index (two rows: source and target nodes)\n",
    "edge_index = torch.tensor(edges_df[['Source', 'Target']].to_numpy().T, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dd2a50-6656-4d16-8392-2eb45d028563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to generate negative edges\n",
    "def generate_negative_edges(num_nodes, existing_edges, num_samples):\n",
    "    \"\"\"\n",
    "    Generate negative edges by sampling random node pairs that are not connected.\n",
    "    \"\"\"\n",
    "    # Convert to set for fast lookup\n",
    "    existing_edges_set = set(map(tuple, existing_edges.T.tolist()))  \n",
    "    negative_edges = set()\n",
    "\n",
    "    while len(negative_edges) < num_samples:\n",
    "        i, j = np.random.randint(0, num_nodes, size=2)\n",
    "        if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "            negative_edges.add((i, j))\n",
    "\n",
    "    return torch.tensor(list(negative_edges), dtype=torch.long)\n",
    "\n",
    "# Generating negative edges\n",
    "num_negative_samples = len(edges_df)  # Same as the number of positive edges\n",
    "negative_edges = generate_negative_edges(len(nodes_df), edge_index, num_negative_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00ee74-2821-42b4-ac3f-048664951e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b531a0a07d784719ae770596a46ae3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/135058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 7/7 [01:52<00:00, 16.10s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 6/6 [01:57<00:00, 19.54s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 7/7 [02:11<00:00, 18.79s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 6/6 [02:01<00:00, 20.30s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 6/6 [02:03<00:00, 20.56s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 6/6 [01:48<00:00, 18.05s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 6/6 [01:37<00:00, 16.23s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 6/6 [01:17<00:00, 12.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# Combining positive and negative edges for training\n",
    "positive_edges = edge_index.T\n",
    "\n",
    "# Convert edge_index to a NetworkX graph\n",
    "graph = nx.Graph()\n",
    "graph.add_edges_from(edge_index.T.tolist())\n",
    "\n",
    "# Initializing and fit Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=32, walk_length=10, num_walks=50, workers=8, p=1, q=2)\n",
    "model = node2vec.fit(window=5, min_count=1, batch_words=4)\n",
    "\n",
    "# Geting node embeddings, handling missing nodes\n",
    "node_embeddings = []\n",
    "for node in range(len(nodes_df)):\n",
    "    if str(node) in model.wv:  # Check if the node exists in the Node2Vec model\n",
    "        node_embeddings.append(model.wv[str(node)])  # Use the embedding from the model\n",
    "    else:\n",
    "        node_embeddings.append(np.zeros(model.wv.vector_size))  # Initialize missing embeddings with zeros\n",
    "\n",
    "# Converting the embeddings list to a NumPy array\n",
    "node_embeddings = np.array(node_embeddings)\n",
    "\n",
    "# Saving the embeddings to a file\n",
    "np.save('node_embeddings.npy', node_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc5ae0-a2ed-4931-8b19-19448e9f33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_keys = list(graph.nodes)\n",
    "print(len(node_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b10657-42d6-4259-9cfc-24ceddeb790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = torch.tensor(node_embeddings, dtype=torch.float)  # Update node features\n",
    "\n",
    "all_edges = torch.cat([positive_edges, negative_edges], dim=0)\n",
    "labels = torch.cat([torch.ones(len(positive_edges)), torch.zeros(len(negative_edges))])\n",
    "\n",
    "# Train-test split for edges\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(\n",
    "    all_edges, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Converting to PyTorch Geometric Data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a707a-11b6-4d9d-a8d1-c039ed345380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Seting a low perplexity (to make sure it's less than the number of nodes in your subset)\n",
    "perplexity_value = 5\n",
    "\n",
    "# Reducing embeddings to 2D using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_value)\n",
    "\n",
    "# Selecting a subset of nodes to visualize (example: top 20 based on popularity/followers or specific genres)\n",
    "subset_size = 20\n",
    "subset_indices = nodes_df.nlargest(subset_size, 'followers').index  \n",
    "\n",
    "# Geting corresponding embeddings for the subset\n",
    "subset_embeddings = node_embeddings[subset_indices]\n",
    "\n",
    "# Applying t-SNE to the subset of embeddings\n",
    "reduced_embeddings = tsne.fit_transform(subset_embeddings)\n",
    "\n",
    "# Creating a scatter plot for the subset\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=reduced_embeddings[:, 0], y=reduced_embeddings[:, 1], s=100, color=\"blue\")\n",
    "\n",
    "# adding labels to the points (nodes)\n",
    "for i, idx in enumerate(subset_indices):\n",
    "    plt.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], nodes_df.loc[idx, 'name'], fontsize=12)\n",
    "\n",
    "plt.title(f\"2D Visualization of Top {subset_size} Node Embeddings\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c8233-df86-427a-92f4-6ac5b25d214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GraphSAGE Model for Link Prediction\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.edge_predictor = torch.nn.Linear(hidden_dim * 2, 1)  # Combining two embeddings\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.conv1(data.x, data.edge_index))\n",
    "        x = F.relu(self.conv2(x, data.edge_index))\n",
    "        return x\n",
    "\n",
    "    def predict_edges(self, x, edges):\n",
    "        # Combine node embeddings for edge prediction\n",
    "        edge_embeds = torch.cat([x[edges[:, 0]], x[edges[:, 1]]], dim=1)\n",
    "        return torch.sigmoid(self.edge_predictor(edge_embeds)).squeeze()\n",
    "\n",
    "# Initializing model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(data.num_node_features, hidden_dim=32).to(device)\n",
    "data = data.to(device)\n",
    "train_edges, train_labels = train_edges.to(device), train_labels.to(device)\n",
    "test_edges, test_labels = test_edges.to(device), test_labels.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18c7a9-0401-467c-8475-62edd4b0ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data)\n",
    "    pred = model.predict_edges(embeddings, train_edges)\n",
    "    loss = F.binary_cross_entropy(pred, train_labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "        pred = model.predict_edges(embeddings, test_edges)\n",
    "        pred_labels = (pred > 0.5).float()  # Binary predictions\n",
    "        accuracy = (pred_labels == test_labels.float()).sum() / len(test_labels)\n",
    "\n",
    "        # Return accuracy, true labels, and predicted labels\n",
    "        return accuracy.item(), test_labels.cpu().numpy(), pred_labels.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e6694-8d43-4069-96ec-2ec124a77dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc, y_true, y_pred = test()\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()  # Extract TN, FP, FN, TP\n",
    "\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(f\"True Negatives (TN): {tn}\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"False Negatives (FN): {fn}\")\n",
    "        print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "        print(\"\\nInterpretation:\")\n",
    "        print(f\"TN: Predicted no collaboration correctly (actual no collaboration)\")\n",
    "        print(f\"FP: Predicted collaboration incorrectly (actual no collaboration)\")\n",
    "        print(f\"FN: Predicted no collaboration incorrectly (actual collaboration)\")\n",
    "        print(f\"TP: Predicted collaboration correctly (actual collaboration)\")\n",
    "\n",
    "        # Optionally, print a classification report\n",
    "        report = classification_report(y_true, y_pred, target_names=[\"No Collaboration\", \"Collaboration\"])\n",
    "        print(f'\\nClassification Report:\\n{report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f14806-847b-463f-bdd5-acd60d28f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Converting existing edges to a set for fast lookup\n",
    "existing_edges_set = set(map(tuple, edge_index.T.tolist()))  # Set of existing edges for quick lookup\n",
    "\n",
    "# Number of unseen pairs to sample\n",
    "num_samples = 300\n",
    "unseen_pairs = []\n",
    "\n",
    "# Randomly sampling node pairs and check if they're not connected\n",
    "while len(unseen_pairs) < num_samples:\n",
    "    i, j = random.sample(range(len(nodes_df)), 2)  # Randomly sample two nodes\n",
    "    \n",
    "    # Ensuring the pair is not already an existing edge\n",
    "    if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "        unseen_pairs.append((i, j))\n",
    "\n",
    "# Converting to tensor\n",
    "unseen_pairs = torch.tensor(unseen_pairs, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639c188-520a-4355-8504-c84889c2bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Seting model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    embeddings = model(data)  # Geting node embeddings\n",
    "    predictions = model.predict_edges(embeddings, unseen_pairs)  # Predicting for unseen pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe936a-d2a8-44c3-ad87-7e0e49adc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking unseen pairs by predicted score\n",
    "sorted_indices = torch.argsort(predictions, descending=True)\n",
    "top_predictions = unseen_pairs[sorted_indices]\n",
    "top_scores = predictions[sorted_indices]\n",
    "\n",
    "# Converting back to artist IDs for better interpretability\n",
    "top_collaborations = [\n",
    "    (nodes_df.iloc[i]['spotify_id'], nodes_df.iloc[j]['spotify_id'], score.item())\n",
    "    for (i, j), score in zip(top_predictions.tolist(), top_scores)\n",
    "]\n",
    "\n",
    "# Displaying top 10 predicted collaborations with artist names\n",
    "\n",
    "for pair in top_collaborations[:10]:\n",
    "    spotify_id_1, spotify_id_2 = pair[0], pair[1]\n",
    "    \n",
    "    # Searching for the Spotify ID in the nodes_df and print the respective artist names\n",
    "    artist_1_name = nodes_df[nodes_df['spotify_id'] == spotify_id_1]['name'].values[0]\n",
    "    artist_2_name = nodes_df[nodes_df['spotify_id'] == spotify_id_2]['name'].values[0]\n",
    "    \n",
    "    print(f\"Artist 1: {artist_1_name}, Artist 2: {artist_2_name}, Predicted Score: {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9008055-1afb-42e8-a66f-dad43176ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the top 10 predictions for visualization\n",
    "top_10_collaborations = top_collaborations[:10]\n",
    "\n",
    "# Prepare data for plotting\n",
    "artist_pairs = [f\"{nodes_df[nodes_df['spotify_id'] == pair[0]]['name'].values[0]} & {nodes_df[nodes_df['spotify_id'] == pair[1]]['name'].values[0]}\" for pair in top_10_collaborations]\n",
    "scores = [pair[2] for pair in top_10_collaborations]\n",
    "\n",
    "# Plotting the top 10 collaborations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(artist_pairs, scores, color='skyblue')\n",
    "plt.xlabel('Predicted Collaboration Score')\n",
    "plt.title('Top 10 Predicted Artist Collaborations')\n",
    "plt.gca().invert_yaxis()  # To show the highest scores on top\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
