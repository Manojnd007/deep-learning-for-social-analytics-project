{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435fada9-1a5d-4006-a9e4-9549b042e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17456/1788718746.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nodes_df = pd.read_csv(\"nodes_cleaned.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Including columns: Spotify ID, Popularity, Followers, Genre columns\n",
    "nodes_df = pd.read_csv(\"nodes_cleaned.csv\")\n",
    "# Including columns: Spotify ID 1, Spotify ID 2  \n",
    "edges_df = pd.read_csv(\"edges_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15201477-59d4-43cc-8a5c-dcbd736c6a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spotify_id               object\n",
       "name                     object\n",
       "followers                object\n",
       "popularity              float64\n",
       "alternative Indie       float64\n",
       "classical_orchestral      int64\n",
       "electronic                int64\n",
       "folk world                int64\n",
       "jazz                      int64\n",
       "hip_hop                   int64\n",
       "latin                     int64\n",
       "metal                     int64\n",
       "pop                       int64\n",
       "randb_Soul                int64\n",
       "reggae_dancehall          int64\n",
       "rock                      int64\n",
       "soundtrack                int64\n",
       "unknown                   int64\n",
       "Unnamed: 18             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dd42ca-b1dd-48d6-923a-be9bea2e3406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_0        object\n",
       "id_1        object\n",
       "artist_0    object\n",
       "artist_1    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e01eb55-a5cb-4831-ad01-c41bac5218f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotify_id               object\n",
      "name                     object\n",
      "followers               float64\n",
      "popularity              float64\n",
      "alternative Indie       float64\n",
      "classical_orchestral      int64\n",
      "electronic                int64\n",
      "folk world                int64\n",
      "jazz                      int64\n",
      "hip_hop                   int64\n",
      "latin                     int64\n",
      "metal                     int64\n",
      "pop                       int64\n",
      "randb_Soul                int64\n",
      "reggae_dancehall          int64\n",
      "rock                      int64\n",
      "soundtrack                int64\n",
      "unknown                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting 'followers' to numeric, setting invalid entries to NaN\n",
    "nodes_df['followers'] = pd.to_numeric(nodes_df['followers'], errors='coerce')\n",
    "\n",
    "# Droping unnecessary column\n",
    "if 'Unnamed: 18' in nodes_df.columns:\n",
    "    nodes_df.drop(columns=['Unnamed: 18'], inplace=True)\n",
    "\n",
    "# Verify the types\n",
    "print(nodes_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d76357-0b48-4da7-a33a-b2db78bb5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop the dupliates and also raise an exception if found.\n",
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    nodes_df = nodes_df.drop_duplicates(subset=['spotify_id']).reset_index(drop=True)\n",
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    raise ValueError(\"Duplicate Spotify IDs found in nodes_df.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15389b53-34de-4725-aa16-ccec902c4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining genre columns\n",
    "genre_columns = [\n",
    "    'alternative Indie', 'classical_orchestral', 'electronic', 'folk world',\n",
    "    'jazz', 'hip_hop', 'latin', 'metal', 'pop', 'randb_Soul',\n",
    "    'reggae_dancehall', 'rock', 'soundtrack', 'unknown'\n",
    "]\n",
    "# Mapping Spotify IDs to indices for graph construction\n",
    "node_index_map = {spotify_id: idx for idx, spotify_id in enumerate(nodes_df['spotify_id'])}\n",
    "edges_df['Source'] = edges_df['id_0'].map(node_index_map)\n",
    "edges_df['Target'] = edges_df['id_1'].map(node_index_map)\n",
    "\n",
    "\n",
    "# Creating edge index (two rows: source and target nodes)\n",
    "edge_index = torch.tensor(edges_df[['Source', 'Target']].to_numpy().T, dtype=torch.long)\n",
    "\n",
    "# Creating node features\n",
    "node_features = torch.tensor(\n",
    "    nodes_df[['popularity', 'followers'] + genre_columns].to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17dd2a50-6656-4d16-8392-2eb45d028563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to generate negative edges\n",
    "def generate_negative_edges(num_nodes, existing_edges, num_samples):\n",
    "    \"\"\"\n",
    "    Generate negative edges by sampling random node pairs that are not connected.\n",
    "    \"\"\"\n",
    "    existing_edges_set = set(map(tuple, existing_edges.T.tolist())) \n",
    "    negative_edges = set()\n",
    "\n",
    "    while len(negative_edges) < num_samples:\n",
    "        i, j = np.random.randint(0, num_nodes, size=2)\n",
    "        # Avoid self-loops and duplicates\n",
    "        if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "            negative_edges.add((i, j))\n",
    "     # Transpose for edge_index format\n",
    "    return torch.tensor(list(negative_edges), dtype=torch.long).T \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd00ee74-2821-42b4-ac3f-048664951e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining positive and negative edges for training\n",
    "positive_edges = edge_index\n",
    "\n",
    "# Combine edges\n",
    "all_edges = torch.cat([positive_edges, negative_edges], dim=1)  # Combine along columns\n",
    "labels = torch.cat([torch.ones(positive_edges.size(1)), torch.zeros(negative_edges.size(1))])\n",
    "\n",
    "# Train-test split for edges\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(\n",
    "    all_edges, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Converting to PyTorch Geometric Data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22c8233-df86-427a-92f4-6ac5b25d214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GraphSAGE Model for Link Prediction\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        # Combining two embeddings for predictor\n",
    "        self.edge_predictor = torch.nn.Linear(hidden_dim * 2, 1) \n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.conv1(data.x, data.edge_index))\n",
    "        x = F.relu(self.conv2(x, data.edge_index))\n",
    "        return x\n",
    "\n",
    "    def predict_edges(self, x, edges):\n",
    "        # Combine node embeddings for edge prediction\n",
    "        edge_embeds = torch.cat([x[edges[:, 0]], x[edges[:, 1]]], dim=1)\n",
    "        return torch.sigmoid(self.edge_predictor(edge_embeds)).squeeze()\n",
    "\n",
    "# Initializing model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(data.num_node_features, hidden_dim=32).to(device)\n",
    "data = data.to(device)\n",
    "train_edges, train_labels = train_edges.to(device), train_labels.to(device)\n",
    "test_edges, test_labels = test_edges.to(device), test_labels.to(device)\n",
    "# LEarning rate is set to 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data)\n",
    "    pred = model.predict_edges(embeddings, train_edges)\n",
    "    loss = F.binary_cross_entropy(pred, train_labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5fe2326-5c08-413b-8d76-35f9d389e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 46798,   8067, 129901,  ..., 106538,   8513,  11159],\n",
      "        [  1753,  17604,   5533,  ...,   2789,  30938,  24254]])\n",
      "Min index: -9223372036854775808, Max index: 143759\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)\n",
    "print(f\"Min index: {edge_index.min()}, Max index: {edge_index.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd18c7a9-0401-467c-8475-62edd4b0ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "        pred = model.predict_edges(embeddings, test_edges)\n",
    "        pred_labels = (pred > 0.5).float()\n",
    "        accuracy = (pred_labels == test_labels.float()).sum() / len(test_labels)\n",
    "    return accuracy.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98e6694-8d43-4069-96ec-2ec124a77dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Found negative indices in 'edge_index' (got -9223372036854775808). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 143760) in your node feature matrix and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         acc \u001b[38;5;241m=\u001b[39m test()\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_edges(embeddings, train_edges)\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(pred, train_labels\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mGraphSAGE.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, data\u001b[38;5;241m.\u001b[39medge_index))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_oh8a_40y.py:173\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    167\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    168\u001b[0m         out,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_oh8a_40y.py:83\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[0;32m---> 83\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tuhh/data_science_3rd_sem/intelligent_system_in_medicine/ism_project_git/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:274\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    275\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound negative indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Found negative indices in 'edge_index' (got -9223372036854775808). Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 143760) in your node feature matrix and try again."
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f14806-847b-463f-bdd5-acd60d28f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Converting existing edges to a set for fast lookup\n",
    "existing_edges_set = set(map(tuple, edge_index.T.tolist())) \n",
    "\n",
    "# Number of unseen pairs of 100 for samples\n",
    "num_samples = 100\n",
    "unseen_pairs = []\n",
    "\n",
    "# Randomly sampling node pairs and check if they're not connected\n",
    "while len(unseen_pairs) < num_samples:\n",
    "    # Randomly sample two nodes\n",
    "    i, j = random.sample(range(len(nodes_df)), 2) \n",
    "    \n",
    "    # Ensuring the pair is not already an existing edge\n",
    "    if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "        unseen_pairs.append((i, j))\n",
    "\n",
    "# Converting to tensor\n",
    "unseen_pairs = torch.tensor(unseen_pairs, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639c188-520a-4355-8504-c84889c2bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do the model evaluation\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    #useing the  data\n",
    "    embeddings = model(data)\n",
    "    predictions = model.predict_edges(embeddings, unseen_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe936a-d2a8-44c3-ad87-7e0e49adc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking unseen pairs by predicted score\n",
    "sorted_indices = torch.argsort(predictions, descending=True)\n",
    "top_predictions = unseen_pairs[sorted_indices]\n",
    "top_scores = predictions[sorted_indices]\n",
    "\n",
    "# Converting back to artist IDs for better interpretability\n",
    "top_collaborations = [\n",
    "    (nodes_df.iloc[i]['spotify_id'], nodes_df.iloc[j]['spotify_id'], score.item())\n",
    "    for (i, j), score in zip(top_predictions.tolist(), top_scores)\n",
    "]\n",
    "\n",
    "# Displaying top 10 predicted collaborations with artist names\n",
    "\n",
    "for pair in top_collaborations[:10]:\n",
    "    spotify_id_1, spotify_id_2 = pair[0], pair[1]\n",
    "    \n",
    "    # Searching for the Spotify ID in the nodes_df and print the respective artist names\n",
    "    artist_1_name = nodes_df[nodes_df['spotify_id'] == spotify_id_1]['name'].values[0]\n",
    "    artist_2_name = nodes_df[nodes_df['spotify_id'] == spotify_id_2]['name'].values[0]\n",
    "    \n",
    "    print(f\"Artist 1: {artist_1_name}, Artist 2: {artist_2_name}, Predicted Score: {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9008055-1afb-42e8-a66f-dad43176ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
