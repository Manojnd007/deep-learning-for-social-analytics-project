{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435fada9-1a5d-4006-a9e4-9549b042e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11015/317092862.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nodes_df = pd.read_csv(\"nodes_cleaned.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Loading cleaned nodes and edges data\n",
    "#columns: Spotify ID, Popularity, Followers, Genre columns\n",
    "nodes_df = pd.read_csv(\"nodes_cleaned.csv\") \n",
    "# Columns: Spotify ID 1, Spotify ID 2\n",
    "edges_df = pd.read_csv(\"edges_cleaned.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9fc823-bbe0-43f9-9b60-28d8231e60b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spotify_id               object\n",
       "name                     object\n",
       "followers                object\n",
       "popularity              float64\n",
       "alternative Indie       float64\n",
       "classical_orchestral      int64\n",
       "electronic                int64\n",
       "folk world                int64\n",
       "jazz                      int64\n",
       "hip_hop                   int64\n",
       "latin                     int64\n",
       "metal                     int64\n",
       "pop                       int64\n",
       "randb_Soul                int64\n",
       "reggae_dancehall          int64\n",
       "rock                      int64\n",
       "soundtrack                int64\n",
       "unknown                   int64\n",
       "Unnamed: 18             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f88720d8-b682-4734-b21d-e5a68a948a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143848 entries, 0 to 143847\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   spotify_id            143848 non-null  object \n",
      " 1   name                  143848 non-null  object \n",
      " 2   followers             143848 non-null  int64  \n",
      " 3   popularity            143848 non-null  float64\n",
      " 4   alternative Indie     143848 non-null  int64  \n",
      " 5   classical_orchestral  143848 non-null  int64  \n",
      " 6   electronic            143848 non-null  int64  \n",
      " 7   folk world            143848 non-null  int64  \n",
      " 8   jazz                  143848 non-null  int64  \n",
      " 9   hip_hop               143848 non-null  int64  \n",
      " 10  latin                 143848 non-null  int64  \n",
      " 11  metal                 143848 non-null  int64  \n",
      " 12  pop                   143848 non-null  int64  \n",
      " 13  randb_Soul            143848 non-null  int64  \n",
      " 14  reggae_dancehall      143848 non-null  int64  \n",
      " 15  rock                  143848 non-null  int64  \n",
      " 16  soundtrack            143848 non-null  int64  \n",
      " 17  unknown               143848 non-null  int64  \n",
      "dtypes: float64(1), int64(15), object(2)\n",
      "memory usage: 19.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert 'followers' column to integer\n",
    "nodes_df['followers'] = pd.to_numeric(nodes_df['followers'], errors='coerce').fillna(0).astype(int)\n",
    "nodes_df['alternative Indie'] = pd.to_numeric(nodes_df['alternative Indie'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Drop the 'Unnamed: 18' column\n",
    "nodes_df = nodes_df.drop(columns=['Unnamed: 18'], errors='ignore')\n",
    "\n",
    "print(nodes_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d76357-0b48-4da7-a33a-b2db78bb5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    nodes_df = nodes_df.drop_duplicates(subset=['spotify_id']).reset_index(drop=True)\n",
    "if nodes_df['spotify_id'].duplicated().any():\n",
    "    raise ValueError(\"Duplicate Spotify IDs found in nodes_df.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15389b53-34de-4725-aa16-ccec902c4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining genre columns\n",
    "genre_columns = [\n",
    "    'alternative Indie', 'classical_orchestral', 'electronic', 'folk world',\n",
    "    'jazz', 'hip_hop', 'latin', 'metal', 'pop', 'randb_Soul',\n",
    "    'reggae_dancehall', 'rock', 'soundtrack', 'unknown'\n",
    "]\n",
    "# Mapping Spotify IDs to indices for graph construction\n",
    "node_index_map = {spotify_id: idx for idx, spotify_id in enumerate(nodes_df['spotify_id'])}\n",
    "edges_df['Source'] = edges_df['id_0'].map(node_index_map)\n",
    "edges_df['Target'] = edges_df['id_1'].map(node_index_map)\n",
    "\n",
    "\n",
    "# Creating edge index (two rows: source and target nodes)\n",
    "edge_index = torch.tensor(edges_df[['Source', 'Target']].to_numpy().T, dtype=torch.long)\n",
    "\n",
    "# Creating node features\n",
    "node_features = torch.tensor(\n",
    "    nodes_df[['popularity', 'followers'] + genre_columns].to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30631162-6f72-435f-9dcd-d064f39d7503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17dd2a50-6656-4d16-8392-2eb45d028563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid indices found: tensor([-9223372036854775808, -9223372036854775808, -9223372036854775808,\n",
      "        -9223372036854775808, -9223372036854775808, -9223372036854775808])\n",
      "Positive edges min: -9223372036854775808 | max: 143759\n",
      "No invalid indices found.\n",
      "No invalid indices found.\n",
      "No invalid indices found.\n",
      "Negative edges min: 0 | max: 143759\n"
     ]
    }
   ],
   "source": [
    "# Check if any invalid indices exist\n",
    "def check_invalid_indices(edge_index, num_nodes):\n",
    "    invalid_indices = (edge_index < 0) | (edge_index >= num_nodes)\n",
    "    if invalid_indices.any():\n",
    "        print(f\"Invalid indices found: {edge_index[invalid_indices]}\")\n",
    "    else:\n",
    "        print(\"No invalid indices found.\")\n",
    "\n",
    "# print for invalid indices in positive and negative edges\n",
    "check_invalid_indices(positive_edges, len(nodes_df))\n",
    "\n",
    "# perform  positive edges\n",
    "positive_edges = edge_index\n",
    "print(f\"Positive edges min: {positive_edges.min()} | max: {positive_edges.max()}\")\n",
    "\n",
    "\n",
    "\n",
    "def generate_negative_edges(num_nodes, existing_edges, num_samples):\n",
    "    \"\"\"\n",
    "    Generate negative edges by sampling random node pairs that are not connected.\n",
    "    \"\"\"\n",
    "    # Convert existing edges to a set for fast lookup\n",
    "    existing_edges_set = set(map(tuple, existing_edges.T.cpu().numpy())) \n",
    "    negative_edges = set()\n",
    "\n",
    "    while len(negative_edges) < num_samples:\n",
    "        i, j = np.random.randint(0, num_nodes, size=2)\n",
    "        # Ensure the edge is valid and not in the existing set\n",
    "        if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "            if 0 <= i < num_nodes and 0 <= j < num_nodes:\n",
    "                negative_edges.add((i, j))\n",
    "\n",
    "    negative_edges_tensor = torch.tensor(list(negative_edges), dtype=torch.long).T\n",
    "    check_invalid_indices(negative_edges_tensor, num_nodes)\n",
    "\n",
    "    return negative_edges_tensor\n",
    "\n",
    "# Generating negative edges\n",
    "num_negative_samples = len(edges_df)\n",
    "negative_edges = generate_negative_edges(len(nodes_df), edge_index, num_negative_samples)\n",
    "\n",
    "check_invalid_indices(negative_edges, len(nodes_df))\n",
    "\n",
    "# perform negative edges\n",
    "negative_edges = generate_negative_edges(len(nodes_df), edge_index, num_negative_samples)\n",
    "print(f\"Negative edges min: {negative_edges.min()} | max: {negative_edges.max()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccae4411-d369-4b75-8ec4-b13577391312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive edges min is -9223372036854775808 and max is 143759\n",
      "Negative edges min is 0 and maximum is 143759\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positive edges min is {edge_index.min()} and max is {edge_index.max()}\") \n",
    "print(f\"Negative edges min is {negative_edges.min()} and maximum is {negative_edges.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bcd7a34-682f-4ca3-91df-bbbe3fcbd25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid indices found in edge_index: tensor([-9223372036854775808, -9223372036854775808, -9223372036854775808,\n",
      "        -9223372036854775808, -9223372036854775808, -9223372036854775808])\n",
      "Edge index after cleaning: tensor([[ 46798,   8067, 129901,  ..., 106538,   8513,  11159],\n",
      "        [  1753,  17604,   5533,  ...,   2789,  30938,  24254]])\n"
     ]
    }
   ],
   "source": [
    "# Check the initial edge_index for invalid indices\n",
    "def check_edge_index_validity(edge_index, num_nodes):\n",
    "    invalid_indices = (edge_index < 0) | (edge_index >= num_nodes)\n",
    "    if invalid_indices.any():\n",
    "        print(f\"Invalid indices found in edge_index: {edge_index[invalid_indices]}\")\n",
    "        edge_index = edge_index[:, ~invalid_indices.any(dim=0)]  # Remove invalid edges\n",
    "        print(f\"Edge index after cleaning: {edge_index}\")\n",
    "    else:\n",
    "        print(\"Edge index is valid.\")\n",
    "    return edge_index\n",
    "\n",
    "# Run this check on your original edge_index\n",
    "edge_index = check_edge_index_validity(edge_index, len(nodes_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a029238c-d5fb-482f-8d94-0d4198522386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edges shape: torch.Size([2, 425668])\n",
      "Test edges shape: torch.Size([2, 106418])\n",
      "Train labels shape: torch.Size([425668])\n",
      "Test labels shape: torch.Size([106418])\n"
     ]
    }
   ],
   "source": [
    "# Combining positive and negative edges for training\n",
    "positive_edges = edge_index  # No need to transpose\n",
    "# Concatenate along columns (dim=1)\n",
    "all_edges = torch.cat([positive_edges, negative_edges], dim=1) \n",
    "labels = torch.cat([torch.ones(positive_edges.shape[1]), torch.zeros(negative_edges.shape[1])])\n",
    "\n",
    "# Train-test split for edges\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(\n",
    "    all_edges.T.numpy(), labels.numpy(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert train and test edges to PyTorch tensors\n",
    "train_edges = torch.tensor(train_edges, dtype=torch.long).T\n",
    "test_edges = torch.tensor(test_edges, dtype=torch.long).T\n",
    "\n",
    "# Convert train and test labels to PyTorch tensors\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
    "\n",
    "# Move the data to the correct device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_edges = train_edges.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "test_edges = test_edges.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "# Convert to PyTorch Geometric Data\n",
    "data = Data(x=node_features, edge_index=all_edges.to(device))\n",
    "\n",
    "# Use test_data for testing (Data object with test edges)\n",
    "test_data = Data(x=node_features, edge_index=test_edges).to(device)\n",
    "\n",
    "# Check the shapes of train and test edges\n",
    "print(\"Train edges shape:\", train_edges.shape)\n",
    "print(\"Test edges shape:\", test_edges.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d22c8233-df86-427a-92f4-6ac5b25d214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GraphSAGE Model for Link Prediction\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.edge_predictor = torch.nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.conv1(data.x, data.edge_index))\n",
    "        x = F.relu(self.conv2(x, data.edge_index))\n",
    "        return x\n",
    "\n",
    "    def predict_edges(self, x, edges):\n",
    "        # Combine node embeddings for edge prediction\n",
    "        edge_embeds = torch.cat([x[edges[0]], x[edges[1]]], dim=1)\n",
    "        # Ensure the output has the shape [num_edges] and flatten to match num_edges\n",
    "        return torch.sigmoid(self.edge_predictor(edge_embeds)).view(-1)  \n",
    "\n",
    "\n",
    "# Initializing model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(data.num_node_features, hidden_dim=32).to(device)\n",
    "data = data.to(device)\n",
    "train_edges, train_labels = train_edges.to(device), train_labels.to(device)\n",
    "test_edges, test_labels = test_edges.to(device), test_labels.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data)\n",
    "    # validating train_edges is a tensor\n",
    "    print(f\"train_edges shape: {train_edges.shape}\")\n",
    "    # Predictions for edges\n",
    "    pred = model.predict_edges(embeddings, train_edges)\n",
    "    print(f\"pred shape: {pred.shape}\") \n",
    "    # Compute binary cross entropy loss\n",
    "    loss = F.binary_cross_entropy(pred, train_labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cd7bd04-a5d0-4063-b1e3-b8bcc9a11309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels shape before training: torch.Size([425668])\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_labels shape before training: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "667def33-44b9-40c0-8d55-8573ffa0d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive edges shape: torch.Size([2, 266040])\n",
      "Negative edges shape: torch.Size([2, 266046])\n",
      "All edges shape (before split): torch.Size([2, 532086])\n",
      "Train edges shape: torch.Size([2, 425668])\n",
      "Test edges shape: torch.Size([2, 106418])\n",
      "Data edge_index shape: torch.Size([2, 532086])\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive edges shape:\", positive_edges.shape)\n",
    "print(\"Negative edges shape:\", negative_edges.shape)\n",
    "print(\"All edges shape (before split):\", all_edges.shape)\n",
    "print(\"Train edges shape:\", train_edges.shape)\n",
    "print(\"Test edges shape:\", test_edges.shape)\n",
    "print(\"Data edge_index shape:\", data.edge_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09513850-5e7d-48fe-b4dc-703f45af62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All edge indices: tensor(0)\n",
      "Positive edge indices: tensor(0)\n",
      "Negative edge indices: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(\"All edge indices:\", all_edges.min())\n",
    "print(\"Positive edge indices:\", positive_edges.min())\n",
    "print(\"Negative edge indices:\", negative_edges.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd18c7a9-0401-467c-8475-62edd4b0ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "        pred = model.predict_edges(embeddings, test_edges)\n",
    "        pred_labels = (pred > 0.5).float()\n",
    "        accuracy = (pred_labels == test_labels.float()).sum() / len(test_labels)\n",
    "    return accuracy.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a98e6694-8d43-4069-96ec-2ec124a77dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 010, Loss: 0.4622, Test Accuracy: 0.7906\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 020, Loss: 0.4111, Test Accuracy: 0.8115\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 030, Loss: 0.4014, Test Accuracy: 0.8175\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 040, Loss: 0.3958, Test Accuracy: 0.8218\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 050, Loss: 0.3909, Test Accuracy: 0.8245\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 060, Loss: 0.3863, Test Accuracy: 0.8280\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 070, Loss: 0.3815, Test Accuracy: 0.8306\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 080, Loss: 0.3760, Test Accuracy: 0.8340\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 090, Loss: 0.3700, Test Accuracy: 0.8375\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 100, Loss: 0.3653, Test Accuracy: 0.8408\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 110, Loss: 0.3613, Test Accuracy: 0.8436\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 120, Loss: 0.3563, Test Accuracy: 0.8441\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 130, Loss: 0.3523, Test Accuracy: 0.8464\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 140, Loss: 0.3487, Test Accuracy: 0.8487\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 150, Loss: 0.3450, Test Accuracy: 0.8507\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 160, Loss: 0.3414, Test Accuracy: 0.8532\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 170, Loss: 0.3398, Test Accuracy: 0.8553\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 180, Loss: 0.3354, Test Accuracy: 0.8549\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 190, Loss: 0.3343, Test Accuracy: 0.8585\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "train_edges shape: torch.Size([2, 425668])\n",
      "pred shape: torch.Size([425668])\n",
      "Epoch 200, Loss: 0.3308, Test Accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        acc = test()\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38f14806-847b-463f-bdd5-acd60d28f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Converting existing edges to a set for fast lookup\n",
    "existing_edges_set = set(map(tuple, edge_index.T.tolist()))  # Set of existing edges for quick lookup\n",
    "\n",
    "# Number of unseen pairs to sample\n",
    "num_samples = 1000\n",
    "unseen_pairs = []\n",
    "\n",
    "# Randomly sampling node pairs and check if they're not connected\n",
    "# Randomly sample two nodes\n",
    "while len(unseen_pairs) < num_samples:\n",
    "    i, j = random.sample(range(len(nodes_df)), 2)  \n",
    "    \n",
    "    # Ensuring the pair is not already an existing edge\n",
    "    if i != j and (i, j) not in existing_edges_set and (j, i) not in existing_edges_set:\n",
    "        unseen_pairs.append((i, j))\n",
    "\n",
    "# Converting to tensor\n",
    "unseen_pairs = torch.tensor(unseen_pairs, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e639c188-520a-4355-8504-c84889c2bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting model to evaluation mode\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    embeddings = model(data)\n",
    "    predictions = model.predict_edges(embeddings, unseen_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85fe936a-d2a8-44c3-ad87-7e0e49adc1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Artist 1: Atlaxsys and  Artist 2: M-A, colloberation Score: 0.0635\n",
      " Artist 1: Boy Warrior and  Artist 2: Meyer, colloberation Score: 0.0204\n"
     ]
    }
   ],
   "source": [
    "# Ranking unseen pairs by predicted score\n",
    "sorted_indices = torch.argsort(predictions, descending=True)\n",
    "top_predictions = unseen_pairs[sorted_indices]\n",
    "top_scores = predictions[sorted_indices]\n",
    "\n",
    "# Converting back to artist IDs for better interpretability\n",
    "top_collaborations = [\n",
    "    (nodes_df.loc[i, 'spotify_id'], nodes_df.loc[j, 'spotify_id'], score.item())\n",
    "    for (i, j), score in zip(top_predictions.tolist(), top_scores)\n",
    "]\n",
    "\n",
    "# Displaying top 5 predicted collaborations with artist names\n",
    "\n",
    "for pair in top_collaborations[:5]:\n",
    "    spotify_id_1, spotify_id_2 = pair[0], pair[1]\n",
    "    \n",
    "    # Searching for the Spotify ID in the nodes_df and print the respective artist names\n",
    "    artist_1_name = nodes_df[nodes_df['spotify_id'] == spotify_id_1]['name'].values[0]\n",
    "    artist_2_name = nodes_df[nodes_df['spotify_id'] == spotify_id_2]['name'].values[0]\n",
    "    \n",
    "    print(f\" Artist 1: {artist_1_name} and  Artist 2: {artist_2_name}, Colloberation Score: {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9008055-1afb-42e8-a66f-dad43176ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0635, 0.0204])\n"
     ]
    }
   ],
   "source": [
    "print(top_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138c445-2eb2-4b9b-8eec-a8eefcf7099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robestness check.\n",
    "node to vec embedding graph as mentioned in the assignment 3.\n",
    "-------------------------------------\n",
    "Existing colloberations prediction.\n",
    "Also the false positive colloberation.\n",
    "------------------------------------\n",
    "validate the prediction in spotify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
